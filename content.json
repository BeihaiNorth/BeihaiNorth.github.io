{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"Liujun Xue","url":"https://beihainorth.github.io"},"pages":[],"posts":[{"title":"How To Install Hadoop on Mac","slug":"hadoop-0-install","date":"2017-10-25T19:08:50.000Z","updated":"2017-10-25T19:14:03.000Z","comments":true,"path":"2017/10/25/hadoop-0-install/","link":"","permalink":"https://beihainorth.github.io/2017/10/25/hadoop-0-install/","excerpt":"This artical tells you how to install the lastest Hadoop version on Mac OS using HomeBrew.","text":"This artical tells you how to install the lastest Hadoop version on Mac OS using HomeBrew. How To Install Hadoop on MacHadoop 2.8.1 macOS Sierra 10.12.6 Step 1: Generate SSL key.123$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys$ chmod 0600 ~/.ssh/authorized_keys Try this command to test. 12$ ssh localhostLast login: Mon Oct 23 20:46:22 2017 Step 2: Install Hadoop using homebrew.12$ brew search hadoop$ brew install hadoop Hadoop will be installed under /usr/local/Cellar/hadoop. Step 3: ConfigurationAll the below configuration files can be found in /usr/local/Cellar/hadoop/2.8.1/libexec/etc/hadoop. hadoop-env.sh 12# The java implementation to use.export JAVA_HOME=\"/Library/Java/Home\" core-site.xml First create a temporary file folder in you file system. You can name it with whatever name you want. Then write the below configuration in the core-site.xml. 123456789101112&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;!-- Replace the value below with the path that you just created. --&gt; &lt;value&gt;/usr/local/Cellar/hadoop/hdfs/tmp&lt;/value&gt; &lt;description&gt;A base for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapred-site.xml 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;localhost:9010&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; yarn-site.xml 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce_shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; To activate the configuration, run: 12$ cd /usr/local/Cellar/hadoop/2.8.1/libexec/bin$ ./hadoop namenode -format Step 4: Start Hadoop123$ cd /usr/local/Cellar/hadoop/2.8.1/libexec/sbin$ ./start-dfs.sh$ ./start-yarn.sh Then you should be able to open these pages: Resource Manager: http://localhost:50070 JobTracker: http://localhost:8088/ Node Specific Info: http://localhost:8042/ After you are done, properly shutdown hadoop. 123$ cd /usr/local/Cellar/hadoop/2.8.1/libexec/sbin$ ./stop-dfs.sh$ ./stop-yarn.sh","categories":[],"tags":[{"name":"Hadoop Tutorial","slug":"Hadoop-Tutorial","permalink":"https://beihainorth.github.io/tags/Hadoop-Tutorial/"}]},{"title":"HDFS Shell Commands","slug":"Commands","date":"2017-09-28T16:45:55.000Z","updated":"2017-09-28T17:02:13.000Z","comments":true,"path":"2017/09/28/Commands/","link":"","permalink":"https://beihainorth.github.io/2017/09/28/Commands/","excerpt":"An introduction to basic use of HDFS shell commands.","text":"An introduction to basic use of HDFS shell commands. All of the hadoop shell commands come with hadoop fs as a start. 1. mkdir &amp; rmdirhadoop fs -mkdir [-p] &lt;paths&gt; It takes paths(urls) as arguments and create certain directory. -p indicating creating parents directories along the paths. hadoop fs -rmdir [--ignore-fail-on-non-empty] URI [URI ...] It deletes a directory. --ignore-fail-on-non-empty: When using wildcards, do not fail if a directory still contains files. 2. puthadoop fs -put [-f][-p] [-l][-d] [ - | &lt;localsrc1&gt; .. ]. &lt;dst&gt; Copy files/folders and put them into destination hdfs directory. Also reads input from stdin and writes to destination file system if the source is set to “-”. 3. copyFromLocalhadoop fs -copyFromLocal &lt;localsrc&gt; URI Similar to the fs -put command, except that the source is restricted to a local file reference. 4. lshadoop fs -ls [-d] [-h] [-R] &lt;args&gt; -d: Directories are listed as plain files. -h: Format file sizes in a human-readable fashion (eg 64.0m instead of 67108864). -R: Recursively list subdirectories encountered. 5. gethadoop fs -get [-ignorecrc] [-crc] [-p] [-f] &lt;src&gt; &lt;localdst&gt; Copy files to the local file system. 6. duhadoop fs -du [-s] [-h] URI [URI ...] Displays sizes of files and directories contained in the given directory or the length of a file in case its just a file. The -s option will result in an aggregate summary of file lengths being displayed, rather than the individual files. The -h option will format file sizes in a “human-readable” fashion (e.g 64.0m instead of 67108864) 7. counthadoop fs -count [-q] [-h] [-v] &lt;paths&gt; Count the number of directories, files and bytes under the paths that match the specified file pattern. The -h option shows sizes in human readable format. The -v option displays a header line. 8. mvhadoop fs -mv URI [URI ...] &lt;dest&gt; Move a file / multiple files from one place to another. 9. cphadoop fs -cp [-f] [-p | -p[topax]] URI [URI ...] &lt;dest&gt; Copy files from source to destination. 10. moveFromLocalhadoop fs -moveFromLocal &lt;localsrc&gt; &lt;dst&gt; Similar to put command, except that the source localsrc is deleted after it’s copied. 11. moveToLocalhadoop fs -moveToLocal [-crc] &lt;src&gt; &lt;dst&gt; Displays a “Not implemented yet” message. 12. getmergehadoop fs -getmerge [-nl] &lt;src&gt; &lt;localdst&gt; 13. appendToFilehadoop fs -appendToFile &lt;localsrc&gt; ... &lt;dst&gt; 14. cathadoop fs -cat [-ignoreCrc] URI [URI ...] Copies source paths to stdout. 15. texthadoop fs -text &lt;src&gt; Takes a source file and outputs the file in text format. 16. touchzhadoop fs -touchz URI [URI ...] Create a file of zero length. An error is returned if the file exists with non-zero length. 17. stathadoop fs -stat [format] &lt;path&gt; ... Print statistics about the file/directory at in the specified format. 18. tailhadoop fs -tail [-f] URI Displays last kilobyte of the file to stdout. Mostly used to check the log file. 19. chgrp &amp; chmod &amp; chownhadoop fs -chgrp [-R] GROUP URI [URI ...] hadoop fs -chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; URI [URI …] hadoop fs -chown [-R] [OWNER][:[GROUP]] URI [URI ] The -R option will make the change recursively through the directory structure. 20. rmhadoop fs -rm [-f] [-r |-R] [-skipTrash] URI [URI ...] Delete files specified as args. If trash is enabled, file system instead moves the deleted file to a trash directory. 21. rmrhadoop fs -rmr [-skipTrash] URI [URI ...] Recursive version of delete. As shown in the command line, this shell command is deprecated. From now on -rm -rshould be used to delete file recursively. 22. checksumhadoop fs -checksum URI Returns the checksum information of a file. 23. dfhadoop fs -df [-h] URI [URI ...] Displays free space. The -h option will format file sizes in a “human-readable” fashion. 24. expungehadoop fs -expunge Permanently delete files in checkpoints older than the retention threshold from trash directory, and create new checkpoint. 25. findhadoop fs -find &lt;path&gt; ... &lt;expression&gt; ... 26. getfaclhadoop fs -getfacl [-R] &lt;path&gt; Displays the Access Control Lists (ACLs) of files and directories. If a directory has a default ACL, then getfacl also displays the default ACL. 27.getfattrhadoop fs -getfattr [-R] -n name | -d [-e en] &lt;path&gt; Displays the extended attribute names and values (if any) for a file or directory. 28. helphadoop fs -help Return usage output. 28. setfattrhadoop fs -setfattr -n name [-v value] | -x name &lt;path&gt; Sets an extended attribute name and value for a file or directory. 29. setrephadoop fs -setrep [-R] [-w] &lt;numReplicas&gt; &lt;path&gt; Changes the replication factor of a file. 30. testhadoop fs -test -[defsz] URI -d: f the path is a directory, return 0. -e: if the path exists, return 0. -f: if the path is a file, return 0. -s: if the path is not empty, return 0. -z: if the file is zero length, return 0. The /temoFolder2 contains a .txt file of 0byte. The results are as follow: 31. usagehadoop fs -usage command Return the help for an individual command.","categories":[],"tags":[{"name":"hadoop hdfs shell","slug":"hadoop-hdfs-shell","permalink":"https://beihainorth.github.io/tags/hadoop-hdfs-shell/"}]},{"title":"2048 Implementation in React","slug":"2048-Implementation-in-React","date":"2017-07-19T13:37:33.000Z","updated":"2017-09-28T16:07:39.000Z","comments":true,"path":"2017/07/19/2048-Implementation-in-React/","link":"","permalink":"https://beihainorth.github.io/2017/07/19/2048-Implementation-in-React/","excerpt":"Just a simple implementation of the popular game 2048 using React. I made it for practicing my programming skills.","text":"Just a simple implementation of the popular game 2048 using React. I made it for practicing my programming skills. IntroductionYou must know the game 2048 first made by Veewo Studio. Well here is a clone of it. Play it here! Source CodeThis game is boostrapped with Create React App, which frees you from configurations like Bable or Webpack and make you focus only on code. The code is open sourced in my github. To get the code and run the game, just: 123git clone https://github.com/BeihaiNorth/2048-React.gitnpm installnpm start Then open http://localhost:3000 in brower to view the running app.","categories":[],"tags":[]},{"title":"Logical Operators in JavaScript","slug":"Logical-Operators-in-JavaScript","date":"2017-06-22T18:19:28.000Z","updated":"2017-06-23T01:28:49.000Z","comments":true,"path":"2017/06/22/Logical-Operators-in-JavaScript/","link":"","permalink":"https://beihainorth.github.io/2017/06/22/Logical-Operators-in-JavaScript/","excerpt":"This artical tells the basic use and smart practice of three logical operators in JavaScript.","text":"This artical tells the basic use and smart practice of three logical operators in JavaScript. DescriptionUnlike in Java or C++, logical operators here can be used with non-bool type. If a value can be converted to true, the value is so-called truthy. If a value can be converted to false, the value is so-called falsy. As logical expressions are evaluated left to right, they are tested using short-circuit evaluation: Expression Returns falsy &#38;&#38; expr false truthy &#38;&#38; expr expr falsy &#124;&#124; expr expr truthy &#124;&#124; expr true !expr false if expr can be converted to true; otherwise, true. Expressions that can be converted to false are: NaN; null; 0; undefined; empty string(&quot;&quot;); Replace if statement with logical ORTaking advantage of the short-circuit feature, we can easily replace if statement with || and make the code shorter. The pattern is as follow: 1234567891011121314//function 1function shortCircuitEvaluation() &#123; doSomething() || doSomethingElse();&#125;function equivalentEvaluation() &#123; var flag = doSomething(); if (!flag) &#123; doSomethingElse(); &#125;&#125;//function 2 :equivalent with function 1function shortCircuitEvaluation() &#123; doSomething() || doSomethingElse();&#125; Example 1 : Replace if12345if(a &gt; 10)&#123; alert('Hello'); &#125;//the code above equals to:a&gt;10&amp;&amp;alert('Hello'); Example 2 : Replace if/else1234567891011121314var b = 0;if(a = 1)&#123; b = 10;&#125;else if(a = 2)&#123; b = 13;&#125;else if(a = 3)&#123; b = 20;&#125;else&#123; b = 0;&#125;//the code above equals to:var b = (a===1&amp;&amp;10)||(a===2&amp;&amp;13)||(a===3&amp;&amp;20)||0;//even better:var b = &#123;'1':10, '2':13, '3':20&#125;[a]||0; As you can see the pattern here is : replace if( condition ){ code } with condition &amp;&amp; code; Replaceif(condition) {code1} else {code2}withcode1 || code2. Example 3 :Determine the browser compatibility 1234567domObj.onkeydown = function(e)&#123; if(e)&#123; //if in firefox, use e e.…… &#125;else&#123; //if in IE, use event event.…… &#125;&#125; While, for shorter: 1234domObj.onkeydown = function(e)&#123; var domObjEvent = e || event; domObjEvent.……&#125; Explaination: If you are using IE, e cannot be used as an event object. e equalsfalse while eventequals true, so event is passed todomObjEvent. If you are using firefox, event cannot be used as an event object. e equalstrue while eventequals false, so e is passed todomObjEvent. Other Smart Practice1. Get the very first ‘truthy’ value1234var a1 = null;var a2 = 24;var b = a1||a2||100;console.log(b); //24 2. Pass default value to function parameter123function f(p)&#123; p = p||10; //if p is not passed, make it 10&#125;","categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://beihainorth.github.io/tags/JavaScript/"}]},{"title":"My own delivery website :)","slug":"FirstTry","date":"2017-06-21T20:05:12.000Z","updated":"2017-06-22T01:38:29.000Z","comments":true,"path":"2017/06/21/FirstTry/","link":"","permalink":"https://beihainorth.github.io/2017/06/21/FirstTry/","excerpt":"","text":"I built a delivery website! Check this out!","categories":[],"tags":[]}]}